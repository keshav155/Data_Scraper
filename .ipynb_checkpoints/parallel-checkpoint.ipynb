{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bs4\n",
    "# !pip install requests, re \n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install selenium\n",
    "# !pip install time\n",
    "# !pip install concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1st block of code\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "import requests , re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1st block of code\n",
    "'''\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\"C:/Users/Keshav Singh/Downloads/chromedriver_win32/chromedriver.exe\", options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_and_URL_fetcher(df , url):\n",
    "    driver.get(url)\n",
    "    host_website = 'https://www.calorieking.com'\n",
    "    more_buttons = driver.find_elements_by_xpath(\"//a[@role = 'button']\")\n",
    "\n",
    "    for x in range(len(more_buttons)):\n",
    "        if more_buttons[x].is_displayed():\n",
    "            driver.execute_script(\"arguments[0].click();\", more_buttons[x])\n",
    "            time.sleep(1)\n",
    "    page_source = driver.page_source\n",
    "    \n",
    "    soup = BeautifulSoup(page_source,'lxml')\n",
    "    food_name = []\n",
    "    links = []\n",
    "    \n",
    "    for url in soup.find_all(\"a\",class_ = \"MuiButtonBase-root MuiListItem-root MuiListItem-gutters MuiListItem-button\",href=True):\n",
    "        links.append(url['href'])\n",
    "    \n",
    "    for name in soup.find_all(\"span\",class_ = \"MuiTypography-root MuiListItemText-primary jss372 MuiTypography-body1 MuiTypography-noWrap MuiTypography-displayBlock\"):\n",
    "        food_name.append(name.text)\n",
    "        \n",
    "    final_urls = [host_website + x for x in links]    \n",
    "    df['Name'] = food_name\n",
    "    df['URL'] = final_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Change URL over here\n",
    "'''\n",
    "\n",
    "restaurant_df = pd.DataFrame()\n",
    "url = \"https://www.calorieking.com/au/en/foods/b/calories-in-mcdonalds-australia/IWLOTE77RgalCE6d8qSOtA?catId=4TmHVi3pQjma8PMa5jjDpQ\"\n",
    "name_and_URL_fetcher(restaurant_df , url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_be_inserted = []\n",
    "np.array(data_to_be_inserted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_url_list = restaurant_df['URL'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching Data for the url\n",
    "def data_fetcher_v2(url):\n",
    "            try: # food item\n",
    "                my_url = url\n",
    "\n",
    "                source = requests.get(my_url).text\n",
    "\n",
    "                soup = BeautifulSoup(source,'lxml')\n",
    "\n",
    "                calories = soup.find('th',class_=\"MuiTableCell-root MuiTableCell-body jss465 MuiTableCell-sizeSmall\").text\n",
    "                calories = calories.split()\n",
    "                calories = calories[1] + \" \" +calories[0] \n",
    "                #print(calories)\n",
    "\n",
    "                kilojoule = soup.find('td',class_=\"MuiTableCell-root MuiTableCell-body MuiTableCell-alignRight MuiTableCell-sizeSmall\").text\n",
    "                kilojoule = kilojoule[1:-1]\n",
    "                #print(kilojoule)\n",
    "\n",
    "                protein = soup.find('th',text = 'Protein').parent.td.text\n",
    "                #print(protein)\n",
    "\n",
    "                total_fats = soup.find('th',text = 'Total Fat').parent.td.text\n",
    "                #print(total_fats)\n",
    "\n",
    "                saturated_fats = soup.find('th',text = 'Saturated Fat').parent.td.text\n",
    "                #print(saturated_fats)\n",
    "\n",
    "                carbohydrates = soup.find('th',text = 'Carbohydrate').parent.td.text\n",
    "                #print(carbohydrates)\n",
    "\n",
    "                sugars = soup.find('th',text = 'Sugars').parent.td.text\n",
    "                #print(sugars)\n",
    "\n",
    "                sodium = soup.find('th',text = 'Sodium').parent.td.text\n",
    "                data_to_insert = [ calories,kilojoule,protein,total_fats,saturated_fats,carbohydrates,sugars,sodium ]\n",
    "             #   data_to_be_inserted_parallel.append(data_to_insert)\n",
    "                print(\"Data has been scraped successfully\")\n",
    "                return data_to_insert\n",
    "    #            print(str(extract_data) + \" has been scraped successfully\")\n",
    "            except: # meal\n",
    "                my_url = url\n",
    "\n",
    "                source = requests.get(my_url).text\n",
    "\n",
    "                soup = BeautifulSoup(source,'lxml')\n",
    "\n",
    "                calories = soup.find('th',class_=\"MuiTableCell-root MuiTableCell-body jss466 MuiTableCell-sizeSmall\").text\n",
    "                calories = calories.split()\n",
    "                calories = calories[1] + \" \" +calories[0] \n",
    "                #print(calories)\n",
    "\n",
    "                kilojoule = soup.find('td',class_=\"MuiTableCell-root MuiTableCell-body MuiTableCell-alignRight MuiTableCell-sizeSmall\").text\n",
    "                kilojoule = kilojoule[1:-1]\n",
    "                #print(kilojoule)\n",
    "\n",
    "                protein = soup.find('th',text = 'Protein').parent.td.text\n",
    "                #print(protein)\n",
    "\n",
    "                total_fats = soup.find('th',text = 'Total Fat').parent.td.text\n",
    "                #print(total_fats)\n",
    "\n",
    "                saturated_fats = soup.find('th',text = 'Saturated Fat').parent.td.text\n",
    "                #print(saturated_fats)\n",
    "\n",
    "                carbohydrates = soup.find('th',text = 'Carbohydrate').parent.td.text\n",
    "                #print(carbohydrates)\n",
    "\n",
    "                sugars = soup.find('th',text = 'Sugars').parent.td.text\n",
    "                #print(sugars)\n",
    "\n",
    "                sodium = soup.find('th',text = 'Sodium').parent.td.text\n",
    "                #print(sodium)\n",
    "                data_to_insert = [ calories,kilojoule,protein,total_fats,saturated_fats,carbohydrates,sugars,sodium ]\n",
    "          #      data_to_be_inserted_parallel.append(data_to_insert)\n",
    "                print(\"Data has been scraped successfully\")\n",
    "                return data_to_insert\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_to_be_inserted\n",
    "#restaurant_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.perf_counter()\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    data_to_be_inserted_parallel = executor.map(data_fetcher_v2, restaurant_url_list)\n",
    "t2 = time.perf_counter()\n",
    "print(f'Finished in {t2-t1} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_be_inserted_parallel = list(data_to_be_inserted_parallel)\n",
    "#data_to_be_inserted_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [\"calories\",\"kilojoule\",\"protein\",\"total_fats\",\"saturated_fats\",\"carbohydrates\",\"sugars\",\"sodium\"]\n",
    "restaurant_df_nutrients = pd.DataFrame(columns=column_list)\n",
    "rows_list = []\n",
    "for row in data_to_be_inserted_parallel:\n",
    "    restaurant_df_nutrients.loc[len(restaurant_df_nutrients)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df_final = pd.concat([restaurant_df, restaurant_df_nutrients], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Change Excel file name here over here\n",
    "'''\n",
    "restaurant_df_final.to_excel(\"data_mcdonalds_parallel.xlsx\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
